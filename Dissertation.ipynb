{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dissertation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNVZnyq9ArW5lHQTe4J6V1K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndyZhang127/temp/blob/main/Dissertation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Loading essential modules"
      ],
      "metadata": {
        "id": "Tp9j5j46XHkj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLpGV5XqSfIT"
      },
      "outputs": [],
      "source": [
        "#Loading Essential Packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Defining necessary functions"
      ],
      "metadata": {
        "id": "ynoMYFDILiHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part A: Producing missing value randomly"
      ],
      "metadata": {
        "id": "85iRkMKF7wHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Producing the missing data randomly\n",
        "def missingRate_Data(df,columns,missing_rate=0):\n",
        "  Source_missing = df.sample(frac=missing_rate)\n",
        "  Source_missing_re=(Source_missing[columns] * 0).replace(0,np.nan)\n",
        "  Source_missing[columns]=Source_missing_re[columns]\n",
        "  index = Source_missing.index\n",
        "  non_missing_df=df.query('index not in @index')\n",
        "  Source_missing_final=pd.concat([non_missing_df,Source_missing])\n",
        "\n",
        "  return Source_missing_final,index,Source_missing,Source_missing,non_missing_df\n",
        "\n"
      ],
      "metadata": {
        "id": "ew-9tTOs1pGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part B: Defining basic imputting methods (mean,mode,median)"
      ],
      "metadata": {
        "id": "QOUi95V_YACu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define replace methods\n",
        "\n",
        "def mean_replace(df,col):\n",
        "  mean=df.agg({col:'mean'}).head(1)[0]\n",
        "  df=df.fillna(mean)\n",
        "  return df\n",
        "\n",
        "def mode_replace(df,col):\n",
        "  mode=df[col].mode()[0]\n",
        "  df=df.fillna(mode)\n",
        "  return df\n",
        "\n",
        "def median_replace(df,col):\n",
        "  median=df.agg({col:'median'}).head(1)[0]\n",
        "  df=df.fillna(median)\n",
        "  return df"
      ],
      "metadata": {
        "id": "do2cR7ArTPGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part C: Defining Algrithm for immputation  (SVR,RF,LSTM,RNN,MLP,GCU,FBPROPHET)"
      ],
      "metadata": {
        "id": "DqXKXvO9YhgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SVRModel(object):\n",
        "\n",
        "    def __init__(self, C=1.0, kernel='rbf', epsilon=0.2, shrinking=True):\n",
        "        self.C = C\n",
        "        self.kernel = kernel\n",
        "        self.shrinking = shrinking\n",
        "        self.epsilon = epsilon\n",
        "        self.buildModel()\n",
        "\n",
        "    def buildModel(self,):\n",
        "        self.model = SVR(C=self.C, cache_size=200, coef0=0.0, degree=3, epsilon=self.epsilon, gamma='auto',\n",
        "            kernel=self.kernel, max_iter=-1, shrinking=self.shrinking, tol=0.001, verbose=False)\n",
        "\n",
        "    def train(self, trainX, trainY):\n",
        "        self.model.fit(trainX, trainY)\n",
        "\n",
        "    def predict(self, testX):\n",
        "        pred = self.model.predict(testX)\n",
        "        return pred\n",
        "\n",
        "class MLP_Model(object):\n",
        "\n",
        "    def __init__(self, inputDim, hiddenNum, outputDim, lr):\n",
        "\n",
        "        self.inputDim = inputDim\n",
        "        self.hiddenNum = hiddenNum\n",
        "        self.outputDim = outputDim\n",
        "        self.opt = keras.optimizers.RMSprop(lr=lr, rho=0.9, epsilon=1e-06)\n",
        "        self.buildModel()\n",
        "\n",
        "    def buildModel(self):\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Dense(self.hiddenNum, input_dim=self.inputDim, activation='relu'))\n",
        "        self.model.add(Dense(1))\n",
        "        self.model.compile(loss='mean_squared_error', optimizer=self.opt)\n",
        "\n",
        "    def train(self, trainX, trainY, epoch, batchSize):\n",
        "        self.model.fit(trainX, trainY, epochs=epoch, batch_size=batchSize, verbose=1)\n",
        "\n",
        "    def predict(self, testX):\n",
        "        pred = self.model.predict(testX)\n",
        "        return pred\n",
        "\n",
        "class RNNsModel(object):\n",
        "    def __init__(self, inputDim, hiddenNum, outputDim, unit, lr):\n",
        "\n",
        "        self.inputDim = inputDim\n",
        "        self.hiddenNum = hiddenNum\n",
        "        self.outputDim = outputDim\n",
        "        self.opt = optimizers.RMSprop(lr=lr, rho=0.9, epsilon=1e-06)\n",
        "        self.buildModel(unit)\n",
        "\n",
        "    def buildModel(self, unit=\"GRU\"):\n",
        "\n",
        "        self.model = Sequential()\n",
        "        if unit == \"GRU\":\n",
        "            self.model.add(GRU(self.hiddenNum, input_shape=(None, self.inputDim)))\n",
        "        elif unit == \"LSTM\":\n",
        "            self.model.add(LSTM(self.hiddenNum, input_shape=(None, self.inputDim)))\n",
        "        elif unit == \"RNN\":\n",
        "            self.model.add(SimpleRNN(self.hiddenNum, input_shape=(None, self.inputDim)))\n",
        "        self.model.add(Dense(self.outputDim))\n",
        "        self.model.compile(loss='mean_squared_error', optimizer=self.opt, metrics=[\"mean_absolute_percentage_error\"])\n",
        "\n",
        "    def train(self, trainX, trainY, epoch, batchSize):\n",
        "        self.model.fit(trainX, trainY, epochs=epoch, batch_size=batchSize, verbose=1, validation_split=0.0)\n",
        "\n",
        "    def predict(self,testX):\n",
        "        pred = self.model.predict(testX)\n",
        "        return pred"
      ],
      "metadata": {
        "id": "70Y5HiQVZUkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part D: Defining validation methods"
      ],
      "metadata": {
        "id": "URve0tVRZOLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define validation methods\n",
        "\n",
        "def MSE(actual,predicted):\n",
        "  MSE = np.square(np.subtract(actual,predicted)).mean() \n",
        "  MSE = math.sqrt(MSE)\n",
        "  return MSE\n",
        "\n",
        "def RMSE(actual,predicted):\n",
        "  MSE = np.square(np.subtract(actual,predicted)).mean() \n",
        "  MSE = math.sqrt(MSE)\n",
        "  RMSE = math.sqrt(MSE)\n",
        "  return RMSE\n",
        "\n",
        "def MAD(actual,predicted):\n",
        "  ''''''\n",
        "  "
      ],
      "metadata": {
        "id": "I61kguRmPlWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part E: Defining visualization methods"
      ],
      "metadata": {
        "id": "lBtHmtmra5St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print all validation result\n",
        "\n",
        "def result_validation(Columns,method='MSE'):\n",
        "    result={}\n",
        "    for  col in Columns:\n",
        "      Temp_actual=Source_Temp[col].tolist()\n",
        "      Temp_predicted=Temp_missing_final_1[col].tolist()\n",
        "      result[col]=MSE(Temp_actual,Temp_predicted)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4A8AkbdVRlH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Deploy different approches on datasets"
      ],
      "metadata": {
        "id": "uHZqR-xM77ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Source Data\n",
        "source_file=pd.read_csv('/content/Occupancy_Estimation.csv')\n",
        "source_file"
      ],
      "metadata": {
        "id": "62qSzA5YJYeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pickup Temp Data\n",
        "Temp_Columns=['Date','Time','S1_Temp','S2_Temp','S3_Temp','S4_Temp']\n",
        "Source_Temp=source_file[Temp_Columns]"
      ],
      "metadata": {
        "id": "jg1WIqwk7IdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Source_Temp"
      ],
      "metadata": {
        "id": "cRX-t7ltAIdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Producing the missing data randomly\n",
        "columns=['S1_Temp','S2_Temp','S3_Temp','S4_Temp']\n",
        "Temp_missing_final_1,Temp_missing_index_1,Source_missing_1,Source_missing_re_1,non_missing_df_1=missingRate_Data(Source_Temp,columns,missing_rate=0.05)\n",
        "Temp_missing_final_2,Temp_missing_index_2,Source_missing_2,Source_missing_re_2,non_missing_df_2=missingRate_Data(Source_Temp,columns,missing_rate=0.10)\n",
        "Temp_missing_final_3,Temp_missing_index_3,Source_missing_3,Source_missing_re_3,non_missing_df_3=missingRate_Data(Source_Temp,columns,missing_rate=0.15)\n",
        "Temp_missing_final_4,Temp_missing_index_4,Source_missing_4,Source_missing_re_4,non_missing_df_4=missingRate_Data(Source_Temp,columns,missing_rate=0.20)\n",
        "Temp_missing_final_5,Temp_missing_index_5,Source_missing_5,Source_missing_re_5,non_missing_df_5=missingRate_Data(Source_Temp,columns,missing_rate=0.30)\n",
        "\n"
      ],
      "metadata": {
        "id": "vOH3A6xL8KkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=Temp_missing_index_1\n",
        "non_missing_df=Source_Temp.query('index not in @index')\n",
        "missing_df=Source_Temp.query('index in @index')"
      ],
      "metadata": {
        "id": "YVXjlEpmFtcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=non_missing_df['datetime','S1_Temp']\n",
        "y_train=missing_df['S1_Temp']\n"
      ],
      "metadata": {
        "id": "94diEm_JHDpo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}